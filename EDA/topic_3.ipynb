{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오프라인 세일즈 데이터 -> 매장별 개폐업 일자 데이터로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202112.     nan 202233. 202252. 202208. 202122. 202234. 202108. 201942.\n",
      " 202121. 202127. 202230. 202134. 202011. 202203. 202144. 202023. 202107.\n",
      " 202102. 202113. 202035. 202032. 202309. 201909. 202008. 202013. 202018.\n",
      " 201911. 202020. 201926. 202009. 201947. 202017. 202215. 202043. 201950.\n",
      " 202031. 201908. 202326. 202010. 202211. 202220. 202037. 201917. 202130.\n",
      " 202052. 202039. 201903. 202110. 202114. 201938. 202104. 201922. 201945.\n",
      " 201912. 201905. 201939. 201935. 202352. 201934. 202024. 201921. 202319.\n",
      " 202040. 202003. 201904. 202205. 202135. 202236. 202226. 201914. 202325.\n",
      " 202350. 201931. 202132. 201932. 202321. 201916. 201915. 201930. 201902.\n",
      " 202315. 202322. 202351. 202120. 201918. 202005. 202117. 202015. 202038.\n",
      " 202046. 202348. 202111. 202235. 202029. 202124. 202335. 202125. 202331.\n",
      " 202250. 202231. 202223. 202004. 202045. 202027. 202241. 202119. 202049.\n",
      " 202139. 202340. 202006. 202304. 202224. 202225. 202228. 202305. 202116.\n",
      " 202036. 201943. 202019. 202033. 202042. 202050. 202146. 202109. 202034.\n",
      " 202137. 202209. 202307. 201913.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터프레임 로드\n",
    "offline_sales = pd.read_csv('../assets/data/offline_offline_wkly_Hazzys_sales.csv')\n",
    "\n",
    "# 오프라인 스토어별 개장일(Open_Store_Week0)과 폐업일(Close_Store_Week0)을 추출하여 새로운 데이터프레임 생성\n",
    "offline_store_info = offline_sales[['Off.Store.Code', 'Off.Store.Name2', 'Open_Store_Week0', 'Close_Store_Week0']]\n",
    "\n",
    "# 중복 제거를 위해 고유한 매장 정보만 추출\n",
    "offline_store_info = offline_store_info.drop_duplicates()\n",
    "\n",
    "# 새로운 데이터프레임 확인\n",
    "print(offline_store_info['Close_Store_Week0'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wk_Year   Sales.Actual\n",
      "0   201901  219852.685182\n",
      "1   201902  107737.669109\n",
      "2   201903   92954.728918\n",
      "3   201904  110051.737891\n",
      "4   201905   83874.081573\n"
     ]
    }
   ],
   "source": [
    "online_Wkly_HZ = pd.read_csv('../assets/data/online_Wkly.HZ.csv')\n",
    "\n",
    "# Wk_Year별로 Sales.Actual의 합산을 구하여 온라인 매출 시계열 데이터 생성\n",
    "online_sales_by_year = online_Wkly_HZ.groupby('Wk_Year')['Sales.Actual'].sum().reset_index()\n",
    "\n",
    "# 데이터 확인\n",
    "print(online_sales_by_year.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Wk_Year   Sales.Actual\n",
      "256   202348  119510.410282\n",
      "257   202349  106832.188627\n",
      "258   202350  112875.840000\n",
      "259   202351   98747.958227\n",
      "260   202352   81682.452045\n"
     ]
    }
   ],
   "source": [
    "print(online_sales_by_year.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에러발생 event_df['date']: 0      200701.0\n",
      "1      200701.0\n",
      "2      200701.0\n",
      "3      200701.0\n",
      "4      200701.0\n",
      "         ...   \n",
      "744    202351.0\n",
      "745    202043.0\n",
      "746    202013.0\n",
      "747    202326.0\n",
      "748    202315.0\n",
      "Name: date, Length: 749, dtype: float64, online_sales_by_year['Wk_Year']: 0      201901\n",
      "1      201902\n",
      "2      201903\n",
      "3      201904\n",
      "4      201905\n",
      "        ...  \n",
      "256    202348\n",
      "257    202349\n",
      "258    202350\n",
      "259    202351\n",
      "260    202352\n",
      "Name: Wk_Year, Length: 261, dtype: int64\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "incompatible merge keys [0] dtype('float64') and dtype('int64'), must be the same type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m에러발생 event_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevents_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, online_sales_by_year[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWk_Year\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monline_sales_by_year[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWk_Year\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 이벤트와 온라인 매출 데이터 병합\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_asof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                           \u001b[49m\u001b[43monline_sales_by_year\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWk_Year\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWk_Year\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# 매출 변화량 계산\u001b[39;00m\n\u001b[0;32m     43\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales.Change\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales.Actual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdiff()\n",
      "File \u001b[1;32mc:\\Users\\YeongminBook\\Desktop\\STUDY\\python\\time-series-analysis\\data-analysis\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:691\u001b[0m, in \u001b[0;36mmerge_asof\u001b[1;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_asof\u001b[39m(\n\u001b[0;32m    441\u001b[0m     left: DataFrame \u001b[39m|\u001b[39m Series,\n\u001b[0;32m    442\u001b[0m     right: DataFrame \u001b[39m|\u001b[39m Series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    454\u001b[0m     direction: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbackward\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    455\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m    456\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[39m    Perform a merge by key distance.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[39m    4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 691\u001b[0m     op \u001b[39m=\u001b[39m _AsOfMerge(\n\u001b[0;32m    692\u001b[0m         left,\n\u001b[0;32m    693\u001b[0m         right,\n\u001b[0;32m    694\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    695\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    696\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    697\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    698\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    699\u001b[0m         by\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m    700\u001b[0m         left_by\u001b[39m=\u001b[39;49mleft_by,\n\u001b[0;32m    701\u001b[0m         right_by\u001b[39m=\u001b[39;49mright_by,\n\u001b[0;32m    702\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    703\u001b[0m         how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39masof\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    704\u001b[0m         tolerance\u001b[39m=\u001b[39;49mtolerance,\n\u001b[0;32m    705\u001b[0m         allow_exact_matches\u001b[39m=\u001b[39;49mallow_exact_matches,\n\u001b[0;32m    706\u001b[0m         direction\u001b[39m=\u001b[39;49mdirection,\n\u001b[0;32m    707\u001b[0m     )\n\u001b[0;32m    708\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\YeongminBook\\Desktop\\STUDY\\python\\time-series-analysis\\data-analysis\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1999\u001b[0m, in \u001b[0;36m_AsOfMerge.__init__\u001b[1;34m(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, how, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m   1994\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mallow_exact_matches must be boolean, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1995\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpassed \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_exact_matches\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1996\u001b[0m     )\n\u001b[0;32m   1997\u001b[0m     \u001b[39mraise\u001b[39;00m MergeError(msg)\n\u001b[1;32m-> 1999\u001b[0m _OrderedMerge\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m   2000\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2001\u001b[0m     left,\n\u001b[0;32m   2002\u001b[0m     right,\n\u001b[0;32m   2003\u001b[0m     on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   2004\u001b[0m     left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m   2005\u001b[0m     right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m   2006\u001b[0m     left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m   2007\u001b[0m     right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m   2008\u001b[0m     how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m   2009\u001b[0m     suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m   2010\u001b[0m     fill_method\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   2011\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\YeongminBook\\Desktop\\STUDY\\python\\time-series-analysis\\data-analysis\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1911\u001b[0m, in \u001b[0;36m_OrderedMerge.__init__\u001b[1;34m(self, left, right, on, left_on, right_on, left_index, right_index, suffixes, fill_method, how)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m   1898\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1899\u001b[0m     left: DataFrame \u001b[39m|\u001b[39m Series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1908\u001b[0m     how: JoinHow \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39masof\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mouter\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1909\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1910\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_method \u001b[39m=\u001b[39m fill_method\n\u001b[1;32m-> 1911\u001b[0m     _MergeOperation\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m   1912\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1913\u001b[0m         left,\n\u001b[0;32m   1914\u001b[0m         right,\n\u001b[0;32m   1915\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   1916\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m   1917\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m   1918\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m   1919\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m   1920\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m   1921\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m   1922\u001b[0m         sort\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# factorize sorts\u001b[39;49;00m\n\u001b[0;32m   1923\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\YeongminBook\\Desktop\\STUDY\\python\\time-series-analysis\\data-analysis\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:802\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[39mif\u001b[39;00m right_drop:\n\u001b[0;32m    800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright\u001b[39m.\u001b[39m_drop_labels_or_levels(right_drop)\n\u001b[1;32m--> 802\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_require_matching_dtypes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft_join_keys, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright_join_keys)\n\u001b[0;32m    803\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tolerance(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys)\n\u001b[0;32m    805\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\YeongminBook\\Desktop\\STUDY\\python\\time-series-analysis\\data-analysis\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2124\u001b[0m, in \u001b[0;36m_AsOfMerge._maybe_require_matching_dtypes\u001b[1;34m(self, left_join_keys, right_join_keys)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[39m# validate index types are the same\u001b[39;00m\n\u001b[0;32m   2123\u001b[0m \u001b[39mfor\u001b[39;00m i, (lk, rk) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(left_join_keys, right_join_keys)):\n\u001b[1;32m-> 2124\u001b[0m     _check_dtype_match(lk, rk, i)\n\u001b[0;32m   2126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_index:\n\u001b[0;32m   2127\u001b[0m     lt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_values\n",
      "File \u001b[1;32mc:\\Users\\YeongminBook\\Desktop\\STUDY\\python\\time-series-analysis\\data-analysis\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2120\u001b[0m, in \u001b[0;36m_AsOfMerge._maybe_require_matching_dtypes.<locals>._check_dtype_match\u001b[1;34m(left, right, i)\u001b[0m\n\u001b[0;32m   2115\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2116\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m   2117\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincompatible merge keys [\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(left\u001b[39m.\u001b[39mdtype)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2118\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(right\u001b[39m.\u001b[39mdtype)\u001b[39m}\u001b[39;00m\u001b[39m, must be the same type\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2119\u001b[0m     )\n\u001b[1;32m-> 2120\u001b[0m \u001b[39mraise\u001b[39;00m MergeError(msg)\n",
      "\u001b[1;31mMergeError\u001b[0m: incompatible merge keys [0] dtype('float64') and dtype('int64'), must be the same type"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 개업일과 폐업일에 대한 이벤트 생성\n",
    "events = []\n",
    "\n",
    "# 개업 이벤트 추가\n",
    "for idx, row in offline_store_info.iterrows():\n",
    "    events.append({'date': row['Open_Store_Week0'], 'event': 'Open', 'store': row['Off.Store.Name2']})\n",
    "\n",
    "# 폐업 이벤트 추가\n",
    "for idx, row in offline_store_info.iterrows():\n",
    "    if pd.notna(row['Close_Store_Week0']):  # 폐업일이 존재하는 경우에만 추가\n",
    "        events.append({'date': row['Close_Store_Week0'], 'event': 'Close', 'store': row['Off.Store.Name2']})\n",
    "\n",
    "# 이벤트 데이터프레임 생성\n",
    "events_df = pd.DataFrame(events)\n",
    "\n",
    "# 주 번호를 날짜로 변환하는 함수\n",
    "def week_to_date(year_week):\n",
    "    year = int(str(year_week)[:4])  # 연도 추출\n",
    "    week = int(str(year_week)[4:])   # 주 번호 추출\n",
    "    return pd.to_datetime(f'{year}-W{week}-1')  # 해당 연도의 첫 번째 날(월요일)\n",
    "\n",
    "# 이벤트 날짜를 datetime 형식으로 변환\n",
    "events_df['date'] = events_df['date'].apply(week_to_date)\n",
    "\n",
    "# 온라인 매출 데이터의 Wk_Year를 날짜로 변환\n",
    "online_sales_by_year['Wk_Year'] = online_sales_by_year['Wk_Year'].apply(week_to_date)\n",
    "# 이벤트와 온라인 매출 데이터 병합\n",
    "merged_df = pd.merge_asof(events_df.sort_values('date'), \n",
    "                           online_sales_by_year.sort_values('Wk_Year'), \n",
    "                           left_on='date', \n",
    "                           right_on='Wk_Year', \n",
    "                           direction='backward')\n",
    "\n",
    "# 매출 변화량 계산\n",
    "merged_df['Sales.Change'] = merged_df['Sales.Actual'].diff()\n",
    "\n",
    "# 개업과 폐업 이벤트에 따른 매출 변화량 시각화\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(merged_df['date'], merged_df['Sales.Actual'], marker='o', label='Online Sales')\n",
    "plt.axvline(x=merged_df['date'][merged_df['event'] == 'Open'].min(), color='g', linestyle='--', label='Store Openings')\n",
    "plt.axvline(x=merged_df['date'][merged_df['event'] == 'Close'].min(), color='r', linestyle='--', label='Store Closures')\n",
    "\n",
    "# 이벤트 표시\n",
    "for i, row in merged_df.iterrows():\n",
    "    plt.text(row['date'], row['Sales.Actual'], row['event'], fontsize=9, ha='center')\n",
    "\n",
    "plt.title('Effect of Store Openings and Closures on Online Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales Actual')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('data-analysis': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "579e555aecd4f6e875a623fd61c720c787d34d649762c53134002dd517314ed5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
